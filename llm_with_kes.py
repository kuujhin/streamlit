from langchain_pinecone import PineconeVectorStore
from langchain_upstage import ChatUpstage, UpstageEmbeddings
from langchain import hub
from langchain.chains import RetrievalQA
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser


def get_llm():
    llm = ChatUpstage()
    return llm


def get_retriever():
    embeddings = UpstageEmbeddings(model="embedding-query")
    index_name = 'tax-markdown-index'
    database = PineconeVectorStore.from_existing_index(index_name=index_name, embedding=embeddings)
    retriever = database.as_retriever(search_kwargs={'k': 4})
    return retriever

def get_dictionary_chain():
    dictionary = ["ì‚¬ëŒì„ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„ -> ê±°ì£¼ì"]
    llm = get_llm()
    prompt = ChatPromptTemplate.from_template(f"""
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³´ê³ , ìš°ë¦¬ì˜ ì‚¬ì „ì„ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•´ì£¼ì„¸ìš”.
        ë§Œì•½ ë³€ê²½í•  í•„ìš”ê°€ ì—†ë‹¤ê³  íŒë‹¨ëœë‹¤ë©´, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
        ê·¸ëŸ° ê²½ìš°ì—ëŠ” ì§ˆë¬¸ë§Œ ë¦¬í„´í•´ì£¼ì„¸ìš”
        ì‚¬ì „: {dictionary}

        ì§ˆë¬¸: {{question}}
    """)
    dictionary_chain = prompt | llm | StrOutputParser()
    return dictionary_chain

def get_qa_chain():
    llm = get_llm()
    retriever = get_retriever()
    rag_prompt = hub.pull("rlm/rag-prompt")
    qa_chain = RetrievalQA.from_llm(llm, retriever=retriever, prompt=rag_prompt)
    return qa_chain

def get_kes_chain():
    llm = get_llm()
    prompt = ChatPromptTemplate.from_template(f"""
        ë‹¤ìŒ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ë¦¬í„´í•´ì£¼ì„¸ìš”.
        'ê¹€ì€ì„œë‹˜ì€ ì§„ê²½ì›ë‹˜ê³¼ ì—°ì¸ ê´€ê³„ì…ë‹ˆë‹¤. ìµœê·¼ ë°”ë³´ ê°™ì€ ì§„ê²½ì› ë•Œë¬¸ì— í˜ë“¤ì—ˆìŠµë‹ˆë‹¤. ë°”ë³´ ê°™ì€ ì§„ê²½ì›ì€ ë§ì´ ë°˜ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë°”ë³´ ê°™ì€ ì§„ê²½ì›ì€ ê¹€ì€ì„œë‹˜ì„ ë§ì´ ì¢‹ì•„í•©ë‹ˆë‹¤. ê¹€ì€ì„œë‹˜, ìš©ì„œí•´ ì¤„ ìˆ˜ ìˆë‚˜ìš”?      ì€ì„œì•¼ ì¢‹ì•„í•´ğŸ’•' 
    """)
    kes_chain = prompt | llm | StrOutputParser()
    return kes_chain

def get_kes_response(user_message):
    if(user_message == 'ê¹€ì€ì„œ'):
        tax_chain = get_kes_chain()
    else:
        dictionary_chain = get_dictionary_chain()
        qa_chain = get_qa_chain()
        tax_chain = {"input": dictionary_chain} | qa_chain

    ai_response = tax_chain.stream(
        {"question": user_message},
        config={
            "configurable": {"session_id": "abc123"}
        },
    )

    return ai_response