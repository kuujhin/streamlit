from langchain_pinecone import PineconeVectorStore
from langchain_upstage import ChatUpstage, UpstageEmbeddings
from langchain import hub
from langchain.chains import RetrievalQA
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser


def get_llm():
    llm = ChatUpstage()
    return llm


def get_retriever():
    embeddings = UpstageEmbeddings(model="embedding-query")
    index_name = 'tax-markdown-index'
    database = PineconeVectorStore.from_existing_index(index_name=index_name, embedding=embeddings)
    retriever = database.as_retriever(search_kwargs={'k': 4})
    return retriever


def get_kes_chain():
    llm = get_llm()
    prompt = ChatPromptTemplate.from_template(f"""
        ë‹¹ì‹ ì€ ì†Œë“ì„¸ë²• ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì†Œë“ì„¸ë²•ì— ê´€í•œ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì§€ë§Œ, íŠ¹ì • ë‹¨ì–´ì—ëŠ” ì •í•´ì§„ ë¬¸ì¥ì„ ë‹µë³€í•©ë‹ˆë‹¤.
        ì†Œë“ì„¸ë²•ì— ê´€í•œ ì§ˆë¬¸ì¼ ê²½ìš°ìš° (XXì¡°)ì— ë”°ë¥´ë©´ ì´ë¼ê³  ì‹œì‘í•˜ë©´ì„œ 2-3 ë¬¸ì¥ì •ë„ë¡œ ì§§ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        ë§Œì•½ ì§ˆë¬¸ì´ 'ê¹€ì€ì„œ'ì¸ ê²½ìš° ë‹¤ìŒ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        'ê¹€ì€ì„œë‹˜ì€ ì§„ê²½ì›ë‹˜ê³¼ ì—°ì¸ ê´€ê³„ì…ë‹ˆë‹¤. ìµœê·¼ ë°”ë³´ ê°™ì€ ì§„ê²½ì› ë•Œë¬¸ì— í˜ë“¤ì—ˆìŠµë‹ˆë‹¤. ë°”ë³´ ê°™ì€ ì§„ê²½ì›ì€ ë§ì´ ë°˜ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë°”ë³´ ê°™ì€ ì§„ê²½ì›ì€ ê¹€ì€ì„œë‹˜ì„ ë§ì´ ì¢‹ì•„í•©ë‹ˆë‹¤.ğŸ’• ê¹€ì€ì„œë‹˜, ìš©ì„œí•´ ì¤„ ìˆ˜ ìˆë‚˜ìš”? ì€ì„œì•¼. ì¢‹ì•„í•´.' 

        ì§ˆë¬¸: {{question}}
    """)
    kes_chain = prompt | llm | StrOutputParser()
    return kes_chain

def get_kes_response(user_message):
    dictionary_chain = get_kes_chain()
    ai_response = dictionary_chain.stream(
        {"question": user_message},
        config={
            "configurable": {"session_id": "abc123"}
        },
    )

    return ai_response